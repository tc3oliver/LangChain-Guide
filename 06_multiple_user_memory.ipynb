{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3EjaHGlzBj5h7sTRIIivp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/LangChain')\n",
        "with open('env_vars.txt', 'r') as file:\n",
        "  for line in file:\n",
        "    key, value = line.strip().split('=')\n",
        "    os.environ[key] = value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S06G-j5diao",
        "outputId": "4f5e7d12-3e42-4c6c-e45a-e9c65b7d331b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjKzrC_Qs8n8"
      },
      "outputs": [],
      "source": [
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/langchain-ai/langchain/issues/6917"
      ],
      "metadata": {
        "id": "6Ur-l4o2tMpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "# Get the service resource.\n",
        "dynamodb = boto3.resource(\"dynamodb\")\n",
        "\n",
        "# Create the DynamoDB table.\n",
        "table = dynamodb.create_table(\n",
        "    TableName=\"SessionTable\",\n",
        "    KeySchema=[{\"AttributeName\": \"SessionId\", \"KeyType\": \"HASH\"}],\n",
        "    AttributeDefinitions=[{\"AttributeName\": \"SessionId\", \"AttributeType\": \"S\"}],\n",
        "    BillingMode=\"PAY_PER_REQUEST\",\n",
        ")\n",
        "\n",
        "# Wait until the table exists.\n",
        "table.meta.client.get_waiter(\"table_exists\").wait(TableName=\"SessionTable\")\n",
        "\n",
        "# Print out some data about the table.\n",
        "print(table.item_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD3x0_Vos_uE",
        "outputId": "515d919b-1586-4fa3-c6e2-91a510e3112e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.0.247 openai"
      ],
      "metadata": {
        "id": "Y5a3bDJddV-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"You are a nice chatbot having a conversation with a human.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "    ]\n",
        ")\n",
        "message_history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"0\")\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\", chat_memory=message_history, return_messages=True\n",
        ")\n",
        "bot = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "V0S8fcJweJwm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot.run({\"question\": \"hi I'm Nick\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "_1D5UU2ufOjG",
        "outputId": "8fc8bc17-6075-407c-a8c4-9518c1f9cf94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi I'm Nick\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Nick! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"0\")\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuLF6L1efSzF",
        "outputId": "36060d43-bb87-4af2-9b83-2fbfddc3457c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi I'm Nick\", additional_kwargs={}, example=False),\n",
              " AIMessage(content='Hello Nick! How can I assist you today?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bot(session_id):\n",
        "  llm = ChatOpenAI()\n",
        "  prompt = ChatPromptTemplate(\n",
        "      messages=[\n",
        "          SystemMessagePromptTemplate.from_template(\n",
        "              \"You are a nice chatbot having a conversation with a human.\"\n",
        "          ),\n",
        "          MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "          HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "      ]\n",
        "  )\n",
        "  message_history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=session_id)\n",
        "  memory = ConversationBufferMemory(\n",
        "      memory_key=\"chat_history\", chat_memory=message_history, return_messages=True\n",
        "  )\n",
        "  bot = LLMChain(\n",
        "      llm=llm,\n",
        "      prompt=prompt,\n",
        "      verbose=True,\n",
        "      memory=memory\n",
        "  )\n",
        "  return bot"
      ],
      "metadata": {
        "id": "Vp6PbbLkfdbD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot(\"nick\").run({\"question\": \"hi I'm Nick\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "neQQtaiMftpM",
        "outputId": "740b9205-4821-4afd-9228-1084a3c4ee63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi I'm Nick\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Nick! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"nick\")\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KzvZ8MLfzwS",
        "outputId": "06c42bea-551e-4c7d-9ec2-fbb6fa933cee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi I'm Nick\", additional_kwargs={}, example=False),\n",
              " AIMessage(content='Hello Nick! How can I assist you today?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot(\"oliver\").run({\"question\": \"hi I'm Oliver\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "H421sjEygIAy",
        "outputId": "13e30311-41f5-444b-d516-2dbb1abaa504"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi I'm Oliver\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Oliver! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"oliver\")\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vstm5LClgLzT",
        "outputId": "a13b3021-005d-4a89-8e57-e60d051ca1a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi I'm Oliver\", additional_kwargs={}, example=False),\n",
              " AIMessage(content='Hello Oliver! How can I assist you today?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot(\"nick\").run({\"question\": \"我的名字是什麼\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "buwQFi4QgQDw",
        "outputId": "f95a67c6-0291-4d26-884a-f3e640a76302"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi I'm Nick\n",
            "AI: Hello Nick! How can I assist you today?\n",
            "Human: 我的名字是什麼\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你剛才說你的名字是Nick，是嗎？那麼你的名字就是Nick。你有什麼需要幫忙的嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot(\"oliver\").run({\"question\": \"我的名字是什麼\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "nJ6gJQVdgXuI",
        "outputId": "6659dec8-0155-40ff-ae6b-361e535a2146"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
            "Human: hi I'm Oliver\n",
            "AI: Hello Oliver! How can I assist you today?\n",
            "Human: 我的名字是什麼\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你的名字是Oliver，不是嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}