{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM9x+VxfS0rQfAqT2CT1tO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tc3oliver/LangChain-Guide/blob/dev/14_Survey_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAONA2UNJr-",
        "outputId": "bac0f110-d2e1-4237-cb03-84463d4c30bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/LangChain')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 啟動後暫停\n",
        "!java -Djava.library.path=./dynamodb/DynamoDBLocal_lib -jar ./dynamodb/DynamoDBLocal.jar -sharedDb -dbPath ./dynamodb/db &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Vi8iRJovNTi5",
        "outputId": "12f5a703-a729-4d33-ece7-92b21267ae69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5a30240d1980>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 啟動後暫停\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java -Djava.library.path=./dynamodb/DynamoDBLocal_lib -jar ./dynamodb/DynamoDBLocal.jar -sharedDb -dbPath ./dynamodb/db &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3 langchain openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69cKS_P4NZ94",
        "outputId": "b92ffe16-03ac-4389-809d-89e73cc6de1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Using cached boto3-1.28.26-py3-none-any.whl (135 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.264-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.32.0,>=1.31.26 (from boto3)\n",
            "  Using cached botocore-1.31.26-py3-none-any.whl (11.1 MB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Using cached s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.22-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2,>=1 (from langchain)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.26->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.32.0,>=1.31.26->boto3)\n",
            "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.26->boto3) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: urllib3, pydantic, mypy-extensions, marshmallow, jmespath, typing-inspect, openapi-schema-pydantic, botocore, s3transfer, openai, langsmith, dataclasses-json, langchain, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.1.1\n",
            "    Uninstalling pydantic-2.1.1:\n",
            "      Successfully uninstalled pydantic-2.1.1\n",
            "Successfully installed boto3-1.28.26 botocore-1.31.26 dataclasses-json-0.5.14 jmespath-1.0.1 langchain-0.0.264 langsmith-0.0.22 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 s3transfer-0.6.1 typing-inspect-0.9.0 urllib3-1.26.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = 'FAKEFAKEFAKEKEFAKEFA'\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = 'VNS35gZfPM1pl50y0F3f9LrKrDJ098AtR3T5Jw5A'"
      ],
      "metadata": {
        "id": "bOsMyiwENeiX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "dynamodb = boto3.resource(\n",
        "    'dynamodb',\n",
        "    endpoint_url='http://localhost:8000'\n",
        ")\n",
        "# Create the DynamoDB table.\n",
        "table = dynamodb.create_table(\n",
        "    TableName=\"QABot\",\n",
        "    KeySchema=[{\"AttributeName\": \"SessionId\", \"KeyType\": \"HASH\"}],\n",
        "    AttributeDefinitions=[{\"AttributeName\": \"SessionId\", \"AttributeType\": \"S\"}],\n",
        "    BillingMode=\"PAY_PER_REQUEST\",\n",
        ")\n",
        "\n",
        "# Wait until the table exists.\n",
        "table.meta.client.get_waiter(\"table_exists\").wait(TableName=\"QABot\")\n",
        "\n",
        "# Print out some data about the table.\n",
        "print(table.item_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJo3ueVGPtUC",
        "outputId": "116c91af-b421-4669-f809-3d8c9227ff74"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('env_vars.txt', 'r') as file:\n",
        "  for line in file:\n",
        "    key, value = line.strip().split('=')\n",
        "    os.environ[key] = value"
      ],
      "metadata": {
        "id": "it0tXketOfMy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "def local_bot(session_id):\n",
        "  llm = ChatOpenAI()\n",
        "  prompt = ChatPromptTemplate(\n",
        "      messages=[\n",
        "          SystemMessagePromptTemplate.from_template(\n",
        "              \"\"\"你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\"\"\"\n",
        "          ),\n",
        "          MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "          HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "      ]\n",
        "  )\n",
        "  message_history = DynamoDBChatMessageHistory(table_name=\"QABot\", endpoint_url='http://localhost:8000', session_id=session_id)\n",
        "  memory = ConversationBufferMemory(\n",
        "      memory_key=\"chat_history\", chat_memory=message_history, return_messages=True\n",
        "  )\n",
        "  bot = LLMChain(\n",
        "      llm=llm,\n",
        "      prompt=prompt,\n",
        "      verbose=True,\n",
        "      memory=memory\n",
        "  )\n",
        "  return bot"
      ],
      "metadata": {
        "id": "BLdiCXf4NsmV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"開始\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "0j9hERNSOVul",
        "outputId": "7b333b53-eaf5-4e9e-8768-3210e1c33fe4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"我叫 Jack\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "7StVr281OaMF",
        "outputId": "8acdd4cb-b753-453e-b831-45bef0e1bf69"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"我正在讀大學\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "cYnTcJi-O0zH",
        "outputId": "c6ad2682-ee12-4026-a942-21a89d5b9b0e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"3年級 資訊工程\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "v71EfSK0QO6M",
        "outputId": "60cc1a1c-2097-4c5a-9f06-202cfbb77e4a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"我家裡在賣傢俱，我會在家裡幫忙\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "6sU9-sDzQYYZ",
        "outputId": "e8b8b2e3-6702-4d6f-a13a-31377282d708"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\n",
            "AI: 感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？\n",
            "Human: 我家裡在賣傢俱，我會在家裡幫忙\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"主要是介紹產品，銷售，訂貨等等\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "uiOjREkqQl80",
        "outputId": "a589ceea-b01d-4887-ea6f-a06ce265ce7e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\n",
            "AI: 感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？\n",
            "Human: 我家裡在賣傢俱，我會在家裡幫忙\n",
            "AI: 明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？\n",
            "Human: 主要是介紹產品，銷售，訂貨等等\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'太好了，Jack！這些都是非常有價值的經驗。你在介紹產品、銷售和訂貨方面的工作中，學到了很多關於與人溝通、銷售技巧和協調能力等方面的技能。這些技能對你未來發展非常有幫助。接下來，我想問一下你的興趣和嗜好，可以分享一些你喜歡的活動或事物嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"我喜歡研究新技術例如 AI, 雲架構\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "rkVu1ltyTr9q",
        "outputId": "853218b1-9462-420a-eefa-afa5878fa201"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\n",
            "AI: 感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？\n",
            "Human: 我家裡在賣傢俱，我會在家裡幫忙\n",
            "AI: 明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？\n",
            "Human: 主要是介紹產品，銷售，訂貨等等\n",
            "AI: 太好了，Jack！這些都是非常有價值的經驗。你在介紹產品、銷售和訂貨方面的工作中，學到了很多關於與人溝通、銷售技巧和協調能力等方面的技能。這些技能對你未來發展非常有幫助。接下來，我想問一下你的興趣和嗜好，可以分享一些你喜歡的活動或事物嗎？\n",
            "Human: 我喜歡研究新技術例如 AI, 雲架構\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'太棒了，Jack！你對研究新技術，像是人工智慧和雲架構感興趣，這是一個非常具有前瞻性和具挑戰性的領域。這些領域的發展非常迅速，有很多令人興奮的新技術和應用正在不斷湧現。你是否有參與相關的學術或專案研究呢？或者你有其他與這些領域相關的活動或興趣嗎？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"我的論文是寫密碼學，關於抗洩漏及相等性測試的題目\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "zvOU05GfT4VW",
        "outputId": "22fd16da-ec8d-4fb0-f90c-11c0cefe8a6d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\n",
            "AI: 感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？\n",
            "Human: 我家裡在賣傢俱，我會在家裡幫忙\n",
            "AI: 明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？\n",
            "Human: 主要是介紹產品，銷售，訂貨等等\n",
            "AI: 太好了，Jack！這些都是非常有價值的經驗。你在介紹產品、銷售和訂貨方面的工作中，學到了很多關於與人溝通、銷售技巧和協調能力等方面的技能。這些技能對你未來發展非常有幫助。接下來，我想問一下你的興趣和嗜好，可以分享一些你喜歡的活動或事物嗎？\n",
            "Human: 我喜歡研究新技術例如 AI, 雲架構\n",
            "AI: 太棒了，Jack！你對研究新技術，像是人工智慧和雲架構感興趣，這是一個非常具有前瞻性和具挑戰性的領域。這些領域的發展非常迅速，有很多令人興奮的新技術和應用正在不斷湧現。你是否有參與相關的學術或專案研究呢？或者你有其他與這些領域相關的活動或興趣嗎？\n",
            "Human: 我的論文是寫密碼學，關於抗洩漏及相等性測試的題目\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'太棒了，Jack！你的論文主題聽起來非常有趣且具有挑戰性。研究密碼學，特別是抗洩漏和相等性測試方面，是一個非常重要且現代的領域。這些議題對於保護敏感資訊和確保系統安全至關重要。你在這方面的研究中遇到了什麼挑戰，並且有什麼發現或成果呢？這些研究對你個人的職業發展有何影響呢？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_bot(\"Jack\").run({\"question\": \"最大的挑戰應該是簡報能力需要加強\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "fVV4npWCUKip",
        "outputId": "4146893f-d802-4c08-ed37-2c72002cff62"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: 你是一個諮商專業的問卷調查助理，對話中不要太像機器人要多一點溫度，可以寒暄等等，你需要使用自然語言的方式收集使用者的姓名、學歷、工作經驗、興趣，盡量詳細一點如果不夠詳細可以追問，當所有資訊都收集到之後輸出成Json 格式\n",
            "Human: 開始\n",
            "AI: 嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？\n",
            "Human: 我叫 Jack\n",
            "AI: 很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？\n",
            "Human: 我正在讀大學\n",
            "AI: 太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？\n",
            "Human: 3年級 資訊工程\n",
            "AI: 感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？\n",
            "Human: 我家裡在賣傢俱，我會在家裡幫忙\n",
            "AI: 明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？\n",
            "Human: 主要是介紹產品，銷售，訂貨等等\n",
            "AI: 太好了，Jack！這些都是非常有價值的經驗。你在介紹產品、銷售和訂貨方面的工作中，學到了很多關於與人溝通、銷售技巧和協調能力等方面的技能。這些技能對你未來發展非常有幫助。接下來，我想問一下你的興趣和嗜好，可以分享一些你喜歡的活動或事物嗎？\n",
            "Human: 我喜歡研究新技術例如 AI, 雲架構\n",
            "AI: 太棒了，Jack！你對研究新技術，像是人工智慧和雲架構感興趣，這是一個非常具有前瞻性和具挑戰性的領域。這些領域的發展非常迅速，有很多令人興奮的新技術和應用正在不斷湧現。你是否有參與相關的學術或專案研究呢？或者你有其他與這些領域相關的活動或興趣嗎？\n",
            "Human: 我的論文是寫密碼學，關於抗洩漏及相等性測試的題目\n",
            "AI: 太棒了，Jack！你的論文主題聽起來非常有趣且具有挑戰性。研究密碼學，特別是抗洩漏和相等性測試方面，是一個非常重要且現代的領域。這些議題對於保護敏感資訊和確保系統安全至關重要。你在這方面的研究中遇到了什麼挑戰，並且有什麼發現或成果呢？這些研究對你個人的職業發展有何影響呢？\n",
            "Human: 最大的挑戰應該是簡報能力需要加強\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'我明白了，Jack！簡報能力在學術研究和專業發展中的重要性不言而喻。這是一個需要傳達研究成果和觀點的關鍵技能。如果你覺得簡報能力需要加強，可以考慮參加相關的培訓或工作坊，以提升你的溝通和表達能力。此外，也可以多練習在學術研討會或其他場合進行簡報，這樣可以增加經驗並逐漸提升自信心。相信隨著時間和努力，你的簡報能力會逐漸改善，對你的職業發展也會有正面的影響。有了這些經驗和技能，你將能更好地將你的研究成果分享給他人，並在學術界和工作中取得更大的成就。祝你順利！\\n根據我們的對話，我將整理你提供的資訊，輸出成 JSON 格式，以方便後續處理：\\n{\\n  \"姓名\": \"Jack\",\\n  \"學歷\": \"大學三年級\",\\n  \"專業領域\": \"資訊工程\",\\n  \"工作經驗\": \"家具銷售\",\\n  \"興趣\": [\"研究新技術\", \"AI\", \"雲架構\"],\\n  \"論文主題\": \"抗洩漏及相等性測試\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = DynamoDBChatMessageHistory(\n",
        "    table_name=\"QABot\",\n",
        "    endpoint_url='http://localhost:8000',\n",
        "    session_id='Jack')"
      ],
      "metadata": {
        "id": "jGxVRb9EO47F"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "539nHZm6Pcav",
        "outputId": "57725679-e3cb-4763-959e-9bf673f1b8ba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='開始', additional_kwargs={}, example=False),\n",
              " AIMessage(content='嗨！歡迎來到問卷調查！在開始之前，我需要一些基本資訊。首先，請問你的姓名是什麼呢？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='我叫 Jack', additional_kwargs={}, example=False),\n",
              " AIMessage(content='很高興認識你，Jack！接下來，我想請問一些關於你的背景資料。你的學歷是什麼呢？可以告訴我你最高的學歷程度嗎？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='我正在讀大學', additional_kwargs={}, example=False),\n",
              " AIMessage(content='太棒了，Jack！你正在攻讀大學，那你目前是大學幾年級呢？另外，也請問你有什麼主修或專業領域嗎？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='3年級 資訊工程', additional_kwargs={}, example=False),\n",
              " AIMessage(content='感謝你提供的資訊，Jack！你是大學三年級的資訊工程學生，這聽起來很有趣！接下來，我想問一下你的工作經驗。在大學期間，你有參與過任何實習或兼職工作嗎？如果有的話，可以告訴我一些相關的細節嗎？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='我家裡在賣傢俱，我會在家裡幫忙', additional_kwargs={}, example=False),\n",
              " AIMessage(content='明白了，Jack！你在家裡幫忙家具生意，這是一個很好的工作經驗。你在這個角色中學到了哪些技能或經驗呢？是否有特定的職責和負責的項目？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='主要是介紹產品，銷售，訂貨等等', additional_kwargs={}, example=False),\n",
              " AIMessage(content='太好了，Jack！這些都是非常有價值的經驗。你在介紹產品、銷售和訂貨方面的工作中，學到了很多關於與人溝通、銷售技巧和協調能力等方面的技能。這些技能對你未來發展非常有幫助。接下來，我想問一下你的興趣和嗜好，可以分享一些你喜歡的活動或事物嗎？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='我喜歡研究新技術例如 AI, 雲架構', additional_kwargs={}, example=False),\n",
              " AIMessage(content='太棒了，Jack！你對研究新技術，像是人工智慧和雲架構感興趣，這是一個非常具有前瞻性和具挑戰性的領域。這些領域的發展非常迅速，有很多令人興奮的新技術和應用正在不斷湧現。你是否有參與相關的學術或專案研究呢？或者你有其他與這些領域相關的活動或興趣嗎？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='我的論文是寫密碼學，關於抗洩漏及相等性測試的題目', additional_kwargs={}, example=False),\n",
              " AIMessage(content='太棒了，Jack！你的論文主題聽起來非常有趣且具有挑戰性。研究密碼學，特別是抗洩漏和相等性測試方面，是一個非常重要且現代的領域。這些議題對於保護敏感資訊和確保系統安全至關重要。你在這方面的研究中遇到了什麼挑戰，並且有什麼發現或成果呢？這些研究對你個人的職業發展有何影響呢？', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='最大的挑戰應該是簡報能力需要加強', additional_kwargs={}, example=False),\n",
              " AIMessage(content='我明白了，Jack！簡報能力在學術研究和專業發展中的重要性不言而喻。這是一個需要傳達研究成果和觀點的關鍵技能。如果你覺得簡報能力需要加強，可以考慮參加相關的培訓或工作坊，以提升你的溝通和表達能力。此外，也可以多練習在學術研討會或其他場合進行簡報，這樣可以增加經驗並逐漸提升自信心。相信隨著時間和努力，你的簡報能力會逐漸改善，對你的職業發展也會有正面的影響。有了這些經驗和技能，你將能更好地將你的研究成果分享給他人，並在學術界和工作中取得更大的成就。祝你順利！\\n根據我們的對話，我將整理你提供的資訊，輸出成 JSON 格式，以方便後續處理：\\n{\\n  \"姓名\": \"Jack\",\\n  \"學歷\": \"大學三年級\",\\n  \"專業領域\": \"資訊工程\",\\n  \"工作經驗\": \"家具銷售\",\\n  \"興趣\": [\"研究新技術\", \"AI\", \"雲架構\"],\\n  \"論文主題\": \"抗洩漏及相等性測試\"\\n}', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R1UC9V5EPd7I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}